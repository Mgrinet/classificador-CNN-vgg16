{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatDog_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mgrinet/classificador-CNN-vgg16/blob/master/CatDog_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEu4XLScMGAz",
        "colab_type": "code",
        "outputId": "5d0cc2d7-8f22-436c-dda2-a3854c9df371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# dimensoes das imagens.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = '/data/train'\n",
        "validation_data_dir = '/data/validation'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Configuracao da augumentacao e imagem que vamos usar para treinamento\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Configuracao da augumentacao e imagem que vamos usar para teste (apenas rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "model.save_weights('/vgg16_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0831 12:08:50.901671 140108253095808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0831 12:08:50.944645 140108253095808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0831 12:08:50.951870 140108253095808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0831 12:08:50.986112 140108253095808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0831 12:08:51.050211 140108253095808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0831 12:08:51.062970 140108253095808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0831 12:08:51.099798 140108253095808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0831 12:08:51.121025 140108253095808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0831 12:08:51.128264 140108253095808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 3000 images belonging to 2 classes.\n",
            "Found 401 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 1011s 8s/step - loss: 0.6589 - acc: 0.6630 - val_loss: 1.3626 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 394s 3s/step - loss: 0.6358 - acc: 0.6660 - val_loss: 0.8214 - val_acc: 0.0286\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 21s 170ms/step - loss: 0.6102 - acc: 0.6700 - val_loss: 1.2734 - val_acc: 0.0494\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 24s 189ms/step - loss: 0.5816 - acc: 0.6715 - val_loss: 1.1484 - val_acc: 0.2195\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 22s 173ms/step - loss: 0.5539 - acc: 0.7210 - val_loss: 2.3187 - val_acc: 0.0169\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 21s 167ms/step - loss: 0.5632 - acc: 0.7160 - val_loss: 0.9609 - val_acc: 0.3364\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 23s 184ms/step - loss: 0.5411 - acc: 0.7120 - val_loss: 1.0291 - val_acc: 0.3208\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 22s 172ms/step - loss: 0.5524 - acc: 0.7230 - val_loss: 1.7318 - val_acc: 0.1208\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 21s 169ms/step - loss: 0.5189 - acc: 0.7355 - val_loss: 1.0853 - val_acc: 0.3857\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 23s 183ms/step - loss: 0.5079 - acc: 0.7505 - val_loss: 0.8393 - val_acc: 0.4481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNNw7BlrChc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "\n",
        "weights_path = 'vgg16_weights.h5'\n",
        "top_model_weights_path = 'fc_model.h5'\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = '/data/train'\n",
        "validation_data_dir = '/data/validation'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "# construir rede VGG16 \n",
        "model = applications.VGG16(weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# modelo pra colocar em cima do conv treinado\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# precisa ter um modelo ja treinado (classificador)\n",
        "top_model.load_weights(top_model_weights_path)\n",
        "\n",
        "# adicionar modelo em cima da base convolucional\n",
        "model.add(top_model)\n",
        "\n",
        "# primeiras 25 camadas nao serao treinadas \n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compilar modelo\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# augumentacao\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "# fine-tune o modelo\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}